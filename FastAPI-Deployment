we use xgboost as the model.

we do data preprocessing - 
1. loading the dataset
2. removing duplicates 
3. handling missing values
4. creating a new feature
5. Encoding categorical features using label encoder

Accuracies - 
1. Accuracy
2. Precision
3. Recall
4. f1-Score

Data.py -> function to preproces the data and then we also use 
apply_label() to convert the output string into readable output eg- >50k or <50k
